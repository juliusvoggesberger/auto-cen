import sys
import os
import subprocess
import time
import shutil

# Specify path to custom autosklearn
custom_autosklearn_path = '/autosklearn'
sys.path.insert(0, custom_autosklearn_path)

# Specify conda.sh path:
conda_path = '/mambaforge/etc/profile.d/conda.sh'


def run_command(command: str, env_name: str, step: str):
    """
    Run a command in a specific conda environment and log the output

    :param command: The command to run
    :param env_name: The name of the conda environment to activate
    :param step: The step number of the pipeline
    """
    # Create log folder:
    timestamp = time.strftime("%Y-%m-%d_%H-%M-%S")
    out_path = f"logs/{timestamp}"
    os.makedirs(out_path, exist_ok=True)
    # log_file = f"{out_path}/errors_step_{step}.log"

    # Construct the command to activate the environment and run the script
    activate_command = (f"source ~{conda_path} && conda activate {env_name} &&"
                        f" {command} && conda deactivate")
                        # f" {command} 2>>{log_file} && conda deactivate")

    subprocess.run(activate_command, shell=True, check=True, executable='/bin/bash')


def main(task_id: int = -1, is_dataset: bool = True, run_name: str = "NONAME", run_time: int = 2400,
         memory_limit_mb: int = 4096, metric: str = "balanced_accuracy", ens_only: bool = False,
         num_folds: int = 1, n_jobs: int = -1, seed: int = 0, delete_temp: bool = False):
    """
    Run the full Q(D)O-ES pipeline for a given task_id/dataset_id. Compiled from the different steps from the README-
    files.

    :param task_id: The task_id to run the pipeline on
    :param is_dataset: If True, task_id is a dataset id, else it is a task id
    :param run_name: The name of the run, used to differentiate between runs
    :param run_time: The time limit for Auto-Sklearn, in seconds
    :param memory_limit_mb: The memory limit for Auto-Sklearn, in MB
    :param metric: The metric to optimize
    :param ens_only: If True, only the ensemble selection methods are run
    :param num_folds: The number of folds to run
    :param n_jobs: The number of cores to use
    :param seed: The seed to use
    :param delete_temp: If True, delete the temporary files after running the pipeline
    """
    is_dataset = "True" if is_dataset else "False"

    # create num_folds string, e.g. "0,1,2,3,4,5,6,7,8,9" (QDO-ES needs it like this...)
    folds_to_run = ",".join([str(i) for i in range(num_folds)])

    if not ens_only:
        # Step 1: Run Auto-Sklearn on the dataset
        print("Step 1: Running Auto-Sklearn on the dataset: {task_id} with seed {seed}")
        run_command(f"python assembled_ask/build_steps/run_ask_on_metatask.py {task_id} {run_time}"
                    f" {memory_limit_mb} {folds_to_run} {metric} {run_name} {is_dataset} {n_jobs} {seed}",
                    "autosklearn_custom", "1")

        # Step 2: Collect the Prediction Data Generated by Auto-Sklearn
        print("Step 2: Collecting the Prediction Data Generated by Auto-Sklearn")
        run_command(f"python assembled_ask/build_steps/run_collect_predictor_data.py {task_id}"
                    f" {folds_to_run} {metric} {run_name} refit save_space {is_dataset} {seed}",
                    "autosklearn_custom", "2")

        # Step 3: Save and Prune the Prediction Data
        print("Step 3: Saving and Pruning the Prediction Data")
        print("Step 3.1: TopN")
        run_command(f"python assembled_ask/build_steps/run_full_metatask_builder.py {task_id}"
                    f" {run_time} {memory_limit_mb} {metric} csv {run_name} TopN {is_dataset} {folds_to_run} {seed}",
                    "autosklearn_custom", "3_1")

        print("Step 3.2: SiloTopN")
        run_command(f"python assembled_ask/build_steps/run_full_metatask_builder.py {task_id}"
                    f" {run_time} {memory_limit_mb} {metric} csv {run_name} SiloTopN {is_dataset} {folds_to_run} {seed}",
                    "autosklearn_custom", "3_2")

        # Copy folder from: f"\benchmark\output\{run_name}\task_{task_id}\final_output\SiloTopN # and TopN
        # to f"\benchmark\input\{run_name}_{task_id}\SiloTopN # and TopN
        silo_path_from = f"benchmark/output/{run_name}/task_{task_id}/final_output/SiloTopN"
        print(f"Moving the output of step 3 to the benchmark folder: {silo_path_from}")
        shutil.move(silo_path_from,
                        f"benchmark/input/{run_name}_{task_id}/SiloTopN")
        shutil.move(f"benchmark/output/{run_name}/task_{task_id}/final_output/TopN",
                        f"benchmark/input/{run_name}_{task_id}/TopN")

    # Step 4: Run the ensemble selection methods
    print("Step 4: Running the ensemble selection methods")
    print("Step 4.1: SingleBest")
    run_command(f'python assembled_ensembles/run_evaluate_ensemble_on_metatask.py {task_id} SiloTopN'
                f' "SingleBest" {metric} {run_name}_{task_id} ensemble_evaluations_qdo no no {folds_to_run} QDO conf_0 '
                f'{n_jobs} {seed}', "qdo", "4_1")

    print("Step 4.2: EnsembleSelection|use_best")
    run_command(f'python assembled_ensembles/run_evaluate_ensemble_on_metatask.py {task_id} SiloTopN'
                f' "EnsembleSelection|use_best" {metric} {run_name}_{task_id} ensemble_evaluations_qdo'
                f' no no {folds_to_run} QDO conf_1 {n_jobs} {seed}', "qdo", "4_2")

    print("Step 4.3: QDOEnsembleSelection|archive_type:sliding")
    run_command(f'python assembled_ensembles/run_evaluate_ensemble_on_metatask.py {task_id} SiloTopN'
                f' "QDOEnsembleSelection|archive_type:sliding|batch_size:20|behavior_space:'
                f'bs_configspace_similarity_and_loss_correlation|buffer_ratio:1.0|crossover:'
                f'two_point_crossover|crossover_probability:0.5|crossover_probability_dynamic|'
                f'elite_selection_method:deterministic|emitter_initialization_method:AllL1|'
                f'max_elites:16|mutation_probability_after_crossover:0.5|'
                f'mutation_probability_after_crossover_dynamic|starting_step_size:1"'
                f' {metric} {run_name}_{task_id} ensemble_evaluations_qdo no no {folds_to_run} QDO conf_2 {n_jobs} {seed}',
                "qdo", "4_3")

    print("Step 4.4: QDOEnsembleSelection|archive_type:quality")
    run_command(f'python assembled_ensembles/run_evaluate_ensemble_on_metatask.py {task_id} SiloTopN'
                f' "QDOEnsembleSelection|archive_type:quality|batch_size:20|crossover:two_point_crossover|'
                f'crossover_probability:0.5|crossover_probability_dynamic|elite_selection_method:deterministic|'
                f'emitter_initialization_method:AllL1|max_elites:16|mutation_probability_after_crossover:0.5|'
                f'mutation_probability_after_crossover_dynamic|starting_step_size:1" {metric} {run_name}_{task_id}'
                f' ensemble_evaluations_qdo no no {folds_to_run} QDO conf_3 {n_jobs} {seed}', "qdo", "4_4")

    # Delete the temporary files (from \benchmark\output\ , \benchmark\input\ and \benchmark\state\)
    # if delete_temp:
    print("Deleting temporary files")
    print(f"Run name: {run_name}")
    shutil.rmtree(f"benchmark/input/{run_name}_{task_id}")
    shutil.rmtree(f"benchmark/output/{run_name}")
    shutil.rmtree(f"benchmark/output/{run_name}_{task_id}")
    shutil.rmtree(f"benchmark/state/{run_name}")
    shutil.rmtree(f"benchmark/state/{run_name}_{task_id}")


if __name__ == "__main__":
    task_id = {6: 3600, 184: 3600, 554: 3600, 1459:3600, 1461: 3600, 
               1489: 3600, 1590: 3600, 4135: 3600, 4538: 3600, 40668: 3600, 
	 	 	40701: 3600, 40926: 3600, 40927: 3600, 40983: 3600, 40996: 3600, 
               41027: 3600, 41156: 3600, 41166: 3600, 41168: 3600, 42769: 3600}
    is_dataset = True
    metric = "balanced_accuracy"
    ens_only = False
    num_folds = 1
    seeds = [123, 456, 789, 1010, 2020]
    delete_temp = True

    # Dictionary to keep track of success status
    success_status = {(t_id, s): False for t_id in task_id.keys() for s in seeds}
    should_retry = True

    def run_task(t_id, seed):
        try:
            run_time_class = int(task_id[t_id])
            memory_limit_mb = -1
            n_jobs = 8  # Should be changed, depending on the available cores

            timestamp = time.strftime("%Y-%m-%d_%H-%M-%S")
            run_name = str(t_id) + "_" + timestamp

            main(task_id=t_id, is_dataset=is_dataset, run_name=run_name, run_time=run_time_class,
                 memory_limit_mb=memory_limit_mb, metric=metric, ens_only=ens_only,
                 num_folds=num_folds, n_jobs=n_jobs, seed=seed, delete_temp=delete_temp)
            return True

        except Exception as e:
            print(f"Error in task {t_id} with seed {seed}: {e}")
            return False

    # Run each task_id with each seed
    for s in seeds:
        for t_id in task_id.keys():
            success_status[(t_id, s)] = run_task(t_id, s)

    if should_retry:
        # Check and rerun failed combinations
        while not all(success_status.values()):
            for (t_id, s), success in success_status.items():
                if not success:
                    success_status[(t_id, s)] = run_task(t_id, s)
